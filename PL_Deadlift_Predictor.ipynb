{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PL Deadlift Predictor.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8"
    },
    "interpreter": {
      "hash": "bc77dd3800523392b346cc37b0ac28b8e216b833125317dbea60e8079bdfbe17"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs7FH53GyrVT",
        "outputId": "1074b04b-7457-4135-fe93-8da39776e2cf"
      },
      "source": [
        "#library installation\n",
        "!pip install category_encoders==2.*\n",
        "!pip install eli5\n",
        "!pip install xgboost\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# file import for google colab\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1QKvc3xzDmU"
      },
      "source": [
        "\n",
        "#import relevant libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import xgboost\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "import joblib\n",
        "from joblib import dump"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Z_Fae1HUzSqb",
        "outputId": "f29aceb7-9397-4113-b404-0eb1486f572c"
      },
      "source": [
        "#import OPL dataset if in colab\n",
        "\n",
        "upload = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTzCS1tCzYqa",
        "outputId": "103e75c6-1588-46a2-da74-e70370b167cd"
      },
      "source": [
        "#begin EDA\n",
        "\n",
        "df = pd.read_csv('openpowerlifting.csv')\n",
        "df.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "L_cnot7SzOwv",
        "outputId": "ae99cae2-b2ca-432c-93af-27c6a9c7d336"
      },
      "source": [
        "#EDA \n",
        "df.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1_gkQn80mnK"
      },
      "source": [
        "#Scope Restriction\n",
        "#Looking through the data it's clear that the observations are both very numerous and diverse in ways that probably don't contribute to the predictive accuracy of our modeling. \n",
        "#We can reduce the scope of the data to something more manageable and increase accuracy by eliminating confounding variables and focusing on those of interest in a comparitively homogenous subset of the data.\n",
        "\n",
        "\n",
        "df = df[(df['Sex'] == 'M')] #Keep only observations of males. This avoids sex differences obscuring the relationships between more useful variables, and enables us to use Wilks coefficients. \n",
        "                            #Females will get their own model.\n",
        "\n",
        "df = df[(df['Equipment'] == 'Raw')] #Keep only observations of raw lifters. The nuances single and multiply equipment add to these observations aren't our concern here.\n",
        "\n",
        "df = df[(df['Division'] == 'Open')] #Similar to our motivation for eliminating sex as a variable, the noise introduced by various age categories is unlikely to be helpful.\n",
        "\n",
        "df = df[(df['Event'] == 'SBD')] #We're intersted in full PL competition and its participants, not specialists.\n",
        "\n",
        "df = df[(df['Place'] != 'DQ')] #the principle means whereby one is disqualified from a powerlifting meet is by \"bombing out,\" eg. failing to produce a passing attempt on one or more of the lifts.\n",
        "                               #These we reject for similar reasons to the specialists\n",
        "df = df[(df['Wilks'] >= 150)] #we restricting our interest to lifters with a wilks score of at least 150 as a very gentle quality control measure. \n",
        "                              #150 wilks is very easy to achieve, and results lower than this are unlikely to say anything useful about training (because very little training went into them) \n",
        "\n",
        "#We additionally drop observations with NaNs in important columns not appropriate for imputation. These drops are mostly redundant after those above; we're mainly catching errors and inconsistency in data entry here. \n",
        "df = df.dropna(subset=['Best3SquatKg', 'Best3BenchKg', 'Best3DeadliftKg', 'Wilks'])\n",
        "\n",
        "#Here we drop the remaining columns that are of no use to us. \n",
        "#Name, Date, Place, Tested, Country, Federation, MeetCountry, MeetState, and Meetname aren't predictively useful.\n",
        "#Sex, Event, Equipment, and Division are all redundant single category categoricals as a result of the decisions we made above. \n",
        "#The columns devoted to each individual attempt are dropped because the relevant information from them (both for our purpose and competition) is summarized in the corresponding \"best\" columns for each lift.\n",
        "#Totalkg, Wilks, McCulloch, Glossbrenner, and IPFPoints are dropped to prevent leakage; these values are each functions of groups of our other columns that include the target. \n",
        "#Leaving any of them in would reduce our \"prediction\" to simple algebra.\n",
        "\n",
        "df = df.drop(columns=['Name', 'Sex', 'Event', 'Equipment', 'Division', 'Squat1Kg', 'Squat2Kg', 'Squat3Kg', 'Squat4Kg', 'Bench1Kg', 'Bench2Kg', 'Bench3Kg', 'Bench4Kg', 'Deadlift1Kg', 'Deadlift2Kg', 'Deadlift3Kg', 'Deadlift4Kg', 'TotalKg', 'Place', 'Wilks', 'McCulloch', 'Glossbrenner', 'IPFPoints', 'Tested', 'Country', 'Federation', 'Date', 'MeetCountry', 'MeetState', 'MeetName'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S6XVaFIHVy_"
      },
      "source": [
        "#Formatting\n",
        "#Categorical features are changed to strings so that they'll place nice with encoders. \n",
        "\n",
        "df['AgeClass'] = df['AgeClass'].astype(str)\n",
        "df['WeightClassKg'] = df['WeightClassKg'].astype(str)\n",
        "\n",
        "#Reset index so that it is no longer full of gaps from our dropped observations\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "7RppVpEW8JNK",
        "outputId": "13aaf944-60c4-4099-c22c-63b169d2cf4e"
      },
      "source": [
        "#EDA post wrangle\n",
        "\n",
        "df['Best3DeadliftKg'].mean()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46KBw-5tIND_"
      },
      "source": [
        "#Feature Engineering\n",
        "\n",
        "#Wilks coefficients \n",
        "#The Wilks formula (and corresponding coefficients) are one of the metrics used to compare perfomance across bodyweights.\n",
        "#We removed the Wilks value from our data because the contribution of a lifter's deadlift to that value creates a leakage problem, but the formula only relates bodyweight to lifted weight (regardless of where that weight came from).\n",
        "#This means we can restore some of the information to our dataset by calculating the contribution of the other lifts to a lifter's Wilks sans deadlift, and possibly add more by doing so for each individual lift (to compare their relative contribution).\n",
        "#These \"[lift] Wilks\" features are simply Wilks calculations with individual lifts instead of totals. The coefficients are unchanged.\"\n",
        "\n",
        "a = -216.0475144\n",
        "b = 16.2606339\n",
        "c = -0.002388645\n",
        "d = -0.00113732\n",
        "e = 0.00000701863\n",
        "f = -0.00000001291\n",
        "\n",
        "df['Squat Wilks'] = df['Best3SquatKg'] * 500 /(a+(b*df['BodyweightKg'])+(c*df['BodyweightKg']**2)+(d*df['BodyweightKg']**3)+(e*df['BodyweightKg']**4)+(f*df['BodyweightKg']**5)) \n",
        "df['Bench Wilks'] = df['Best3BenchKg'] * 500 /(a+(b*df['BodyweightKg'])+(c*df['BodyweightKg']**2)+(d*df['BodyweightKg']**3)+(e*df['BodyweightKg']**4)+(f*df['BodyweightKg']**5)) \n",
        "\n",
        "#Analogy to anthropometry\n",
        "#Folk wisdom says that some amount of the difference between lifters' relative ability in the lifts are a result of differing anthropometry (specifically limb lengths and the resulting leverages)\n",
        "#While there isn't any anthropometic data in the dataset, we can attempt to test these assumptions by making some of our own to approximate it. \n",
        "#If we assume that relatively longer limbed men tend to be heavier (simply by virtue of being larger), and that longer arms are beneficial in deadlift while being detrimental in the bench press, the ratio between these might be useful to our model. \n",
        "#We can similarly use the ratio between bench and squat to see if short arms (manifested by a relatively more powerful bench) translates to a relatively less powerful deadlift. \n",
        "\n",
        "df['Bench:Bodyweight Ratio'] = df['Best3BenchKg']/df['BodyweightKg']\n",
        "df['Bench:Squat Ratio'] = df['Best3BenchKg']/df['Best3SquatKg']\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzwAe7le9vzW",
        "outputId": "b3213fd0-955b-4a3e-9a5a-6059892e1af1"
      },
      "source": [
        "#EDA post feature engineering\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jKE1zRE0taDw",
        "outputId": "48b41914-09b9-4494-c00c-71c389f115b8"
      },
      "source": [
        "#Exploratory Visualization\n",
        "#Scatterplots to get a rough picture of the relationships between each of the individual features and the target\n",
        "\n",
        "df.plot.scatter(x='BodyweightKg', y='Best3DeadliftKg')\n",
        "df.plot.scatter(x='Best3SquatKg', y='Best3DeadliftKg')\n",
        "df.plot.scatter(x='Best3BenchKg', y='Best3DeadliftKg')\n",
        "df.plot.scatter(x='Bench:Squat Ratio', y='Best3DeadliftKg')\n",
        "df.plot.scatter(x='Bench:Bodyweight Ratio', y='Best3DeadliftKg')\n",
        "df.plot.scatter(x='Squat Wilks', y='Best3DeadliftKg')\n",
        "df.plot.scatter(x='Bench Wilks', y='Best3DeadliftKg')\n",
        "df.plot.scatter(x='Age', y='Best3DeadliftKg')\n",
        "df.plot.scatter(x='WeightClassKg', y='Best3DeadliftKg')\n",
        "df.plot.scatter(x='AgeClass', y='Best3DeadliftKg')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vPqYy-buUjg"
      },
      "source": [
        "#Split\n",
        "#Data split into train, val, and test sets\n",
        "\n",
        "target = df['Best3DeadliftKg']\n",
        "features = df.drop(columns='Best3DeadliftKg')\n",
        "y = target\n",
        "X = features\n",
        "\n",
        "X_remain, X_test, y_remain, y_test = train_test_split(X, y, test_size=.15, random_state=666)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_remain, y_remain, test_size=.2, random_state=666)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucdORm84utz0",
        "outputId": "d14b03a3-513c-4745-c7ee-b64817cbbd44"
      },
      "source": [
        "#Subset size comparison\n",
        "\n",
        "len(X_train), len(X_val), len(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2EYcd4Pu97B",
        "outputId": "d92fe3f9-1432-46e6-99b8-1b127656efde"
      },
      "source": [
        "#Baseline Metrics\n",
        "\n",
        "#For baseline metrics we're using the mean absolute and percentage errors that we would see if we just predicted the mean target value in the validation set. \n",
        "\n",
        "\n",
        "guess = y_val.mean()\n",
        "guess_prediction = [guess] * len(y_val)\n",
        "baseline_mae = mean_absolute_error(y_val, guess_prediction)\n",
        "baseline_mape = mean_absolute_percentage_error(y_val, guess_prediction)\n",
        "\n",
        "guess, baseline_mae, baseline_mape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c-w87AuyZhU",
        "outputId": "07a93417-579d-486a-dff6-42f67c28909b"
      },
      "source": [
        "# Simple Linear Regression\n",
        "\n",
        "slr = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='mean'),\n",
        "    StandardScaler(),\n",
        "    LinearRegression())\n",
        "slr.fit(X_train, y_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywl6u4lhyujb",
        "outputId": "c97e1d19-2d34-4f35-a495-120fc33b54b5"
      },
      "source": [
        "#testing simple linear regression metrics\n",
        "#error less than half of baseline\n",
        "\n",
        "y_pred1 = slr.predict(X_val)\n",
        "linear_mae = mean_absolute_error(y_val, y_pred1)\n",
        "linear_mape = mean_absolute_percentage_error(y_val, y_pred1)\n",
        "\n",
        "linear_mae, linear_mape\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEbLFZfGPHU4",
        "outputId": "ae13072a-0b28-4605-9952-1bd1af7caec8"
      },
      "source": [
        "#Examining how different features contribute to the model\n",
        "#Permutation importances\n",
        "\n",
        "#transforming feature matricies for use outside of pipeline and fitting transformed model\n",
        "transformers = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='mean'),\n",
        "    StandardScaler()\n",
        ")\n",
        "\n",
        "X_train_transformed = transformers.fit_transform(X_train)\n",
        "X_val_transformed = transformers.transform(X_val)\n",
        "\n",
        "slr_perm = LinearRegression()\n",
        "slr_perm.fit(X_train_transformed, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdpgysoazD_p",
        "outputId": "2d621ae0-2f07-4559-f991-33fc93331c4a"
      },
      "source": [
        "#fitting permuter\n",
        "\n",
        "permuter_ml = PermutationImportance(\n",
        "    slr_perm,  \n",
        "    n_iter=5, \n",
        "    random_state=666\n",
        ")\n",
        "\n",
        "permuter_ml.fit(X_val_transformed, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-0DxKkTFiT-",
        "outputId": "210bd9ee-c125-4398-c411-02acefc66f36"
      },
      "source": [
        "#View and Interpret Results\n",
        "#Looking at the ordering of these features it seems as though there may be something to the anthropometric explanation of relative deadlift strength difference after all; \n",
        "#both of the features that relate bench press to bodyweight score high. I'm somewhat surprised that Bench:Squat ratio isn't more predictive than it is.\n",
        "#What isn't surprising in hindsight is how unimportant Age is. Excluding non-open categories from the data seems to have excluded competitors for whom age would be a significant factor in their performance. \n",
        "\n",
        "feature_names = X_val.columns.tolist()\n",
        "pd.Series(permuter_ml.feature_importances_, feature_names).sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elBe8t-6UA6q",
        "outputId": "7c88d0f8-40f9-4e8a-f615-5f38fe94c344"
      },
      "source": [
        "#Gradient Boosting\n",
        "\n",
        "\n",
        "gb = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='mean'),\n",
        "    StandardScaler(),\n",
        "    XGBRegressor(n_estimators=100, max_depth=5, random_state=666, n_jobs=-1))\n",
        "gb.fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_nXuQh1dUjq",
        "outputId": "1ab1bc5a-6a0d-48b7-a23e-71f75fa883c0"
      },
      "source": [
        "#testing gradient boosting metrics\n",
        "#Gradient Boosting model performs roughly as well as the linear model. \n",
        "\n",
        "\n",
        "y_pred2 = gb.predict(X_val)\n",
        "gb_mae = mean_absolute_error(y_val, y_pred2)\n",
        "gb_mape = mean_absolute_percentage_error(y_val, y_pred2)\n",
        "\n",
        "gb_mae, gb_mape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju4kq0FkgWpc",
        "outputId": "d5e43269-8f0d-46f8-b634-36fd420cfd13"
      },
      "source": [
        "#Examining Feature Interaction in Gradient Boosting Model\n",
        "\n",
        "#fitting transformed model, reusing permuted sets \n",
        "gb_perm = XGBRegressor()\n",
        "gb_perm.fit(X_train_transformed, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehQ2m8HZg6GT",
        "outputId": "492733a8-f420-4a4d-c671-ed251191071d"
      },
      "source": [
        "#fitting permuter for gradient boosting model\n",
        "\n",
        "gb_permuter = PermutationImportance(\n",
        "    gb_perm,  \n",
        "    n_iter=5, \n",
        "    random_state=666\n",
        ")\n",
        "\n",
        "gb_permuter.fit(X_val_transformed, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-7DwsuKhvnr",
        "outputId": "17c3185e-3e40-4a0c-bfd5-21bf10873bca"
      },
      "source": [
        "#View and Interpret Results\n",
        "#This ordering of features is somewhat different from the one we saw with the linear model (mainly in the relative importance of Best3SquatKg). \n",
        "#Given how much redundant information there is across features we should probably take their permutation importances with a grain of salt.\n",
        "\n",
        "feature_names = X_val.columns.tolist()\n",
        "pd.Series(gb_permuter.feature_importances_, feature_names).sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df2 = pd.read_csv('openpowerlifting.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#The same wrangling procedures mirrored to predict BestDeadliftKg for female lifters\n",
        "\n",
        "df2 = df2[(df2['Sex'] == 'F')] \n",
        "df2 = df2[(df2['Equipment'] == 'Raw')] \n",
        "df2 = df2[(df2['Division'] == 'Open')] \n",
        "df2 = df2[(df2['Event'] == 'SBD')] \n",
        "df2 = df2[(df2['Place'] != 'DQ')]                                \n",
        "df2 = df2[(df2['Wilks'] >= 150)] \n",
        "\n",
        "df2 = df2.dropna(subset=['Best3SquatKg', 'Best3BenchKg', 'Best3DeadliftKg', 'Wilks'])\n",
        "\n",
        "\n",
        "df2 = df2.drop(columns=['Name', 'Sex', 'Event', 'Equipment', 'Division', 'Squat1Kg', 'Squat2Kg', 'Squat3Kg', 'Squat4Kg', 'Bench1Kg', 'Bench2Kg', 'Bench3Kg', 'Bench4Kg', 'Deadlift1Kg', 'Deadlift2Kg', 'Deadlift3Kg', 'Deadlift4Kg', 'TotalKg', 'Place', 'Wilks', 'McCulloch', 'Glossbrenner', 'IPFPoints', 'Tested', 'Country', 'Federation', 'Date', 'MeetCountry', 'MeetState', 'MeetName'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Formatting\n",
        "df2['AgeClass'] = df2['AgeClass'].astype(str)\n",
        "df2['WeightClassKg'] = df2['WeightClassKg'].astype(str)\n",
        "\n",
        "#Reset index \n",
        "df2 = df2.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Feature Engineering\n",
        "\n",
        "#Wilks coefficients \n",
        "#The Wilks coefficients for females are different from those in the male formula, which is one of the motivating reasons to model the two subsets seperately. \n",
        "\n",
        "a = 594.31747775582\n",
        "b = -27.23842536447\n",
        "c = 0.82112226871\n",
        "d = -0.00930733913\n",
        "e = 0.00004731582\n",
        "f = -0.00000009054\n",
        "\n",
        "df2['Squat Wilks'] = df2['Best3SquatKg'] * 500 /(a+(b*df2['BodyweightKg'])+(c*df2['BodyweightKg']**2)+(d*df2['BodyweightKg']**3)+(e*df2['BodyweightKg']**4)+(f*df2['BodyweightKg']**5)) \n",
        "df2['Bench Wilks'] = df2['Best3BenchKg'] * 500 /(a+(b*df2['BodyweightKg'])+(c*df2['BodyweightKg']**2)+(d*df2['BodyweightKg']**3)+(e*df2['BodyweightKg']**4)+(f*df2['BodyweightKg']**5)) \n",
        "\n",
        "#Ratios\n",
        "df2['Bench:Bodyweight Ratio'] = df2['Best3BenchKg']/df2['BodyweightKg']\n",
        "df2['Bench:Squat Ratio'] = df2['Best3BenchKg']/df2['Best3SquatKg']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Split\n",
        "#Data split into train, val, and test sets\n",
        "\n",
        "target = df2['Best3DeadliftKg']\n",
        "features = df2.drop(columns='Best3DeadliftKg')\n",
        "yf = target\n",
        "Xf = features\n",
        "\n",
        "Xf_remain, Xf_test, yf_remain, yf_test = train_test_split(Xf, yf, test_size=.15, random_state=666)\n",
        "\n",
        "Xf_train, Xf_val, yf_train, yf_val = train_test_split(Xf_remain, yf_remain, test_size=.2, random_state=666)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Baseline Metrics\n",
        "\n",
        "#baseline errors for females are predictably smaller in absolute terms but about the same in relative terms \n",
        "\n",
        "\n",
        "guess = yf_val.mean()\n",
        "guess_prediction = [guess] * len(yf_val)\n",
        "baseline_maef = mean_absolute_error(yf_val, guess_prediction)\n",
        "baseline_mapef = mean_absolute_percentage_error(yf_val, guess_prediction)\n",
        "\n",
        "guess, baseline_maef, baseline_mapef"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple Linear Regression\n",
        "\n",
        "slrf = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='mean'),\n",
        "    StandardScaler(),\n",
        "    LinearRegression())\n",
        "slrf.fit(Xf_train, yf_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#testing simple linear regression metrics\n",
        "#errors for females also about half of baseline\n",
        "\n",
        "yf_pred1 = slrf.predict(Xf_val)\n",
        "linear_maef = mean_absolute_error(yf_val, yf_pred1)\n",
        "linear_mapef = mean_absolute_percentage_error(yf_val, yf_pred1)\n",
        "\n",
        "linear_maef, linear_mapef"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#Permutation importances for female linear model\n",
        "\n",
        "#transforming feature matricies for use outside of pipeline and fitting transformed model\n",
        "transformersf = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='mean'),\n",
        "    StandardScaler()\n",
        ")\n",
        "\n",
        "Xf_train_transformed = transformersf.fit_transform(Xf_train)\n",
        "Xf_val_transformed = transformersf.transform(Xf_val)\n",
        "\n",
        "slrf_perm = LinearRegression()\n",
        "slrf_perm.fit(Xf_train_transformed, yf_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#fitting permuter\n",
        "\n",
        "permuter_fl = PermutationImportance(\n",
        "    slrf_perm,  \n",
        "    n_iter=5, \n",
        "    random_state=666\n",
        ")\n",
        "\n",
        "permuter_fl.fit(Xf_val_transformed, yf_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#View and Interpret Results\n",
        "#feature importances for the female linear model are similar those for the male version \n",
        "\n",
        "feature_namesf = Xf_val.columns.tolist()\n",
        "pd.Series(permuter_fl.feature_importances_, feature_namesf).sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Gradient Boosting\n",
        "\n",
        "gbf = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='mean'),\n",
        "    StandardScaler(),\n",
        "    XGBRegressor(n_estimators=100, max_depth=5, random_state=666, n_jobs=-1))\n",
        "gbf.fit(Xf_train, yf_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#testing gradient boosting metrics\n",
        "#in the female case the gradient boosting model underperforms slightly relative to the linear model \n",
        "\n",
        "\n",
        "yf_pred2 = gb.predict(Xf_val)\n",
        "gbf_maef = mean_absolute_error(yf_val, yf_pred2)\n",
        "gbf_mapef = mean_absolute_percentage_error(yf_val, yf_pred2)\n",
        "\n",
        "gbf_maef, gbf_mapef"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Examining Feature Interaction in Gradient Boosting Model\n",
        "\n",
        "#fitting transformed model, reusing permuted sets \n",
        "gbf_perm = XGBRegressor()\n",
        "gbf_perm.fit(Xf_train_transformed, yf_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#fitting permuter\n",
        "\n",
        "permuter_gbf = PermutationImportance(\n",
        "    gbf_perm,  \n",
        "    n_iter=5, \n",
        "    random_state=666\n",
        ")\n",
        "\n",
        "permuter_gbf.fit(Xf_val_transformed, yf_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#View and Interpret Results\n",
        "#Feature importances for the female gradient boosting model are somewhat more balanced than their male counterparts, albeit still dominated by BestSquatKg\n",
        "\n",
        "feature_namesf = Xf_val.columns.tolist()\n",
        "pd.Series(permuter_gbf.feature_importances_, feature_namesf).sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Permutation Importances Formatted\n",
        "\n",
        "#male linear model\n",
        "eli5.show_weights(permuter_ml, top=None, feature_names=feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#male gradient boosting model\n",
        "eli5.show_weights(gb_permuter, top=None, feature_names=feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#female linear model\n",
        "eli5.show_weights(permuter_fl, top=None, feature_names=feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#female gradient boosting model\n",
        "eli5.show_weights(permuter_gbf, top=None, feature_names=feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Final Error Metrics with Test Sets\n",
        "#male linear model\n",
        "\n",
        "y_pred1_test = slr.predict(X_test)\n",
        "linear_mae_test = mean_absolute_error(y_test, y_pred1_test)\n",
        "linear_mape_test = mean_absolute_percentage_error(y_test, y_pred1_test)\n",
        "\n",
        "linear_mae_test, linear_mape_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#male gradient boosting model\n",
        "y_pred2_test = gb.predict(X_test)\n",
        "gb_mae_test = mean_absolute_error(y_test, y_pred2_test)\n",
        "gb_mape_test = mean_absolute_percentage_error(y_test, y_pred2_test)\n",
        "\n",
        "gb_mae_test, gb_mape_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#female linear model\n",
        "yf_pred1_test = slrf.predict(Xf_test)\n",
        "linear_maef_test = mean_absolute_error(yf_test, yf_pred1_test)\n",
        "linear_mapef_test = mean_absolute_percentage_error(yf_test, yf_pred1_test)\n",
        "\n",
        "linear_maef_test, linear_mapef_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#female gradient boosting model\n",
        "yf_pred2_test = gb.predict(Xf_test)\n",
        "gbf_maef_test = mean_absolute_error(yf_test, yf_pred2_test)\n",
        "gbf_mapef_test = mean_absolute_percentage_error(yf_test, yf_pred2_test)\n",
        "\n",
        "gbf_maef_test, gbf_mapef_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#getting coefs for linear models\n",
        "#male model\n",
        "\n",
        "male_linear = slr.named_steps['linearregression']\n",
        "print(male_linear.coef_),\n",
        "print(male_linear.intercept_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#female model\n",
        "\n",
        "female_linear = slrf.named_steps['linearregression']\n",
        "print(female_linear.coef_),\n",
        "print(female_linear.intercept_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pipelines are slr, gb, slrf, gbf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#getting versions for libraries\n",
        "\n",
        "\n",
        "\n",
        "print(f'joblib=={joblib.__version__}')\n",
        "print(f'scikit-learn=={sklearn.__version__}')\n",
        "print(f'category_encoders=={ce.__version__}')\n",
        "print(f'xgboost=={xgboost.__version__}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pickling pipelines\n",
        "\n",
        "dump(slr, 'slr.joblib', compress=True)\n",
        "dump(gb, 'gb.joblib', compress=True)\n",
        "dump(slrf, 'slrf.joblib', compress=True)\n",
        "dump(gbf, 'gbf.joblib', compress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#male linear predictor function\n",
        "\n",
        "def mlpredict(age, bodyweight, squat, bench):\n",
        "    \n",
        "    a = -216.0475144\n",
        "    b = 16.2606339\n",
        "    c = -0.002388645\n",
        "    d = -0.00113732\n",
        "    e = 0.00000701863\n",
        "    f = -0.00000001291\n",
        "\n",
        "    mswilks = squat * 500 /(a+(b*bodyweight)+(c*bodyweight**2)+(d*bodyweight**3)+(e*bodyweight**4)+(f*bodyweight**5))\n",
        "    mbwilks = bench * 500 /(a+(b*bodyweight)+(c*bodyweight**2)+(d*bodyweight**3)+(e*bodyweight**4)+(f*bodyweight**5))\n",
        "    mbbr = bench/bodyweight\n",
        "    mbsr = bench/squat\n",
        "    age_class = '24-34'\n",
        "\n",
        "    if (age>=5)&(age<=12):\n",
        "        age_class = '5-12'\n",
        "    elif (age>=13)&(age<=15):\n",
        "        age_class = '13-15'\n",
        "    elif (age>=16)&(age<=17):\n",
        "        age_class = '16-17'\n",
        "    elif (age>=18)&(age<=19):\n",
        "        age_class = '18-19'\n",
        "    elif (age>=20)&(age<=23):\n",
        "        age_class = '20-23'\n",
        "    elif (age>=24)&(age<=34):\n",
        "        age_class = '24-34'\n",
        "    elif (age>=35)&(age<=39):\n",
        "        age_class = '35-39'\n",
        "    elif (age>=40)&(age<=44):\n",
        "        age_class = '40-44'\n",
        "    elif (age>=45)&(age<=49):\n",
        "        age_class = '45-49'\n",
        "    elif (age>=50)&(age<=54):\n",
        "        age_class = '50-54'\n",
        "    elif (age>=55)&(age<=59):\n",
        "        age_class = '55-59'\n",
        "    elif (age>=60)&(age<=64):\n",
        "        age_class = '60-64'\n",
        "    elif (age>=65)&(age<=69):\n",
        "        age_class = '65-69'\n",
        "    elif (age>=70)&(age<=74):\n",
        "        age_class = '70-74'\n",
        "    elif (age>=75)&(age<=79):\n",
        "        age_class = '75-79'\n",
        "    elif (age>=80)&(age<=999):\n",
        "        age_class = '80-999'\n",
        "\n",
        "    weight_class = '93'\n",
        "    if bodyweight<50:\n",
        "        weight_class = '48'\n",
        "    elif (bodyweight>=50)&(bodyweight<=66):\n",
        "        weight_class = '66'\n",
        "    elif (bodyweight>66)&(bodyweight<=75):\n",
        "        weight_class = '75'\n",
        "    elif (bodyweight>75)&(bodyweight<=83):\n",
        "        weight_class = '83'\n",
        "    elif (bodyweight>83)&(bodyweight<=93):\n",
        "        weight_class = '93'\n",
        "    elif (bodyweight>93)&(bodyweight<=100):\n",
        "        weight_class = '100'\n",
        "    elif (bodyweight>100)&(bodyweight<=120):\n",
        "        weight_class = '120'\n",
        "    elif (bodyweight>120)&(bodyweight<=140):\n",
        "        weight_class = '140'\n",
        "    elif (bodyweight>140):\n",
        "        weight_class = '140+'\n",
        "    \n",
        "    \n",
        "    temp = pd.DataFrame(\n",
        "        columns=['Age', 'AgeClass', 'BodyweightKg', 'WeightClassKg', 'Best3SquatKg', 'Best3BenchKg', 'Squat Wilks', 'Bench Wilks', 'Bench:Bodyweight Ratio', 'Bench:Squat Ratio'], \n",
        "        data=[[age, age_class, bodyweight, weight_class, squat, bench, mswilks, mbwilks, mbbr, mbsr]]\n",
        "    )\n",
        "    y_pred = slr.predict(temp)[0]\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#male gradient boosting predictor function\n",
        "\n",
        "def mgbpredict(age, bodyweight, squat, bench):\n",
        "    \n",
        "    a = -216.0475144\n",
        "    b = 16.2606339\n",
        "    c = -0.002388645\n",
        "    d = -0.00113732\n",
        "    e = 0.00000701863\n",
        "    f = -0.00000001291\n",
        "\n",
        "    mswilks = squat * 500 /(a+(b*bodyweight)+(c*bodyweight**2)+(d*bodyweight**3)+(e*bodyweight**4)+(f*bodyweight**5))\n",
        "    mbwilks = bench * 500 /(a+(b*bodyweight)+(c*bodyweight**2)+(d*bodyweight**3)+(e*bodyweight**4)+(f*bodyweight**5))\n",
        "    mbbr = bench/bodyweight\n",
        "    mbsr = bench/squat\n",
        "    age_class = '24-34'\n",
        "\n",
        "    if (age>=5)&(age<=12):\n",
        "        age_class = '5-12'\n",
        "    elif (age>=13)&(age<=15):\n",
        "        age_class = '13-15'\n",
        "    elif (age>=16)&(age<=17):\n",
        "        age_class = '16-17'\n",
        "    elif (age>=18)&(age<=19):\n",
        "        age_class = '18-19'\n",
        "    elif (age>=20)&(age<=23):\n",
        "        age_class = '20-23'\n",
        "    elif (age>=24)&(age<=34):\n",
        "        age_class = '24-34'\n",
        "    elif (age>=35)&(age<=39):\n",
        "        age_class = '35-39'\n",
        "    elif (age>=40)&(age<=44):\n",
        "        age_class = '40-44'\n",
        "    elif (age>=45)&(age<=49):\n",
        "        age_class = '45-49'\n",
        "    elif (age>=50)&(age<=54):\n",
        "        age_class = '50-54'\n",
        "    elif (age>=55)&(age<=59):\n",
        "        age_class = '55-59'\n",
        "    elif (age>=60)&(age<=64):\n",
        "        age_class = '60-64'\n",
        "    elif (age>=65)&(age<=69):\n",
        "        age_class = '65-69'\n",
        "    elif (age>=70)&(age<=74):\n",
        "        age_class = '70-74'\n",
        "    elif (age>=75)&(age<=79):\n",
        "        age_class = '75-79'\n",
        "    elif (age>=80)&(age<=999):\n",
        "        age_class = '80-999'\n",
        "\n",
        "    weight_class = '93'\n",
        "    if bodyweight<50:\n",
        "        weight_class = '48'\n",
        "    elif (bodyweight>=50)&(bodyweight<=66):\n",
        "        weight_class = '66'\n",
        "    elif (bodyweight>66)&(bodyweight<=75):\n",
        "        weight_class = '75'\n",
        "    elif (bodyweight>75)&(bodyweight<=83):\n",
        "        weight_class = '83'\n",
        "    elif (bodyweight>83)&(bodyweight<=93):\n",
        "        weight_class = '93'\n",
        "    elif (bodyweight>93)&(bodyweight<=100):\n",
        "        weight_class = '100'\n",
        "    elif (bodyweight>100)&(bodyweight<=120):\n",
        "        weight_class = '120'\n",
        "    elif (bodyweight>120)&(bodyweight<=140):\n",
        "        weight_class = '140'\n",
        "    elif (bodyweight>140):\n",
        "        weight_class = '140+'\n",
        "    \n",
        "    \n",
        "    temp = pd.DataFrame(\n",
        "        columns=['Age', 'AgeClass', 'BodyweightKg', 'WeightClassKg', 'Best3SquatKg', 'Best3BenchKg', 'Squat Wilks', 'Bench Wilks', 'Bench:Bodyweight Ratio', 'Bench:Squat Ratio'], \n",
        "        data=[[age, age_class, bodyweight, weight_class, squat, bench, mswilks, mbwilks, mbbr, mbsr]]\n",
        "    )\n",
        "    y_pred = gb.predict(temp)[0]\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Xf_train['WeightClassKg'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#female linear predictor function\n",
        "\n",
        "def flpredict(age, bodyweight, squat, bench):\n",
        "    \n",
        "    a = 594.31747775582\n",
        "    b = -27.23842536447\n",
        "    c = 0.82112226871\n",
        "    d = -0.00930733913\n",
        "    e = 0.00004731582\n",
        "    f = -0.00000009054\n",
        "\n",
        "    fswilks = squat * 500 /(a+(b*bodyweight)+(c*bodyweight**2)+(d*bodyweight**3)+(e*bodyweight**4)+(f*bodyweight**5))\n",
        "    fbwilks = bench * 500 /(a+(b*bodyweight)+(c*bodyweight**2)+(d*bodyweight**3)+(e*bodyweight**4)+(f*bodyweight**5))\n",
        "    fbbr = bench/bodyweight\n",
        "    fbsr = bench/squat\n",
        "    age_class = '24-34'\n",
        "\n",
        "    if (age>=5)&(age<=12):\n",
        "        age_class = '5-12'\n",
        "    elif (age>=13)&(age<=15):\n",
        "        age_class = '13-15'\n",
        "    elif (age>=16)&(age<=17):\n",
        "        age_class = '16-17'\n",
        "    elif (age>=18)&(age<=19):\n",
        "        age_class = '18-19'\n",
        "    elif (age>=20)&(age<=23):\n",
        "        age_class = '20-23'\n",
        "    elif (age>=24)&(age<=34):\n",
        "        age_class = '24-34'\n",
        "    elif (age>=35)&(age<=39):\n",
        "        age_class = '35-39'\n",
        "    elif (age>=40)&(age<=44):\n",
        "        age_class = '40-44'\n",
        "    elif (age>=45)&(age<=49):\n",
        "        age_class = '45-49'\n",
        "    elif (age>=50)&(age<=54):\n",
        "        age_class = '50-54'\n",
        "    elif (age>=55)&(age<=59):\n",
        "        age_class = '55-59'\n",
        "    elif (age>=60)&(age<=64):\n",
        "        age_class = '60-64'\n",
        "    elif (age>=65)&(age<=69):\n",
        "        age_class = '65-69'\n",
        "    elif (age>=70)&(age<=74):\n",
        "        age_class = '70-74'\n",
        "    elif (age>=75):\n",
        "        age_class = '75-79'\n",
        "\n",
        "    weight_class = '93'\n",
        "    if bodyweight<=50:\n",
        "        weight_class = '44'\n",
        "    elif (bodyweight>50)&(bodyweight<=52):\n",
        "        weight_class = '52'\n",
        "    elif (bodyweight>52)&(bodyweight<=63):\n",
        "        weight_class = '63'\n",
        "    elif (bodyweight>63)&(bodyweight<=72):\n",
        "        weight_class = '72'\n",
        "    elif (bodyweight>72)&(bodyweight<=84):\n",
        "        weight_class = '84'\n",
        "    elif (bodyweight>84)&(bodyweight<=90):\n",
        "        weight_class = '90'\n",
        "    elif (bodyweight>90)&(bodyweight<=100):\n",
        "        weight_class = '100'\n",
        "    elif (bodyweight>100):\n",
        "        weight_class = '100+'\n",
        "\n",
        "    temp = pd.DataFrame(\n",
        "        columns=['Age', 'AgeClass', 'BodyweightKg', 'WeightClassKg', 'Best3SquatKg', 'Best3BenchKg', 'Squat Wilks', 'Bench Wilks', 'Bench:Bodyweight Ratio', 'Bench:Squat Ratio'], \n",
        "        data=[[age, age_class, bodyweight, weight_class, squat, bench, fswilks, fbwilks, fbbr, fbsr]]\n",
        "    )\n",
        "    y_pred = slrf.predict(temp)[0]\n",
        "    return y_pred\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flpredict(32, 100, 215, 152)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#female gradient boosting predictor function\n",
        "\n",
        "def fgbpredict(age, bodyweight, squat, bench):\n",
        "    \n",
        "    a = 594.31747775582\n",
        "    b = -27.23842536447\n",
        "    c = 0.82112226871\n",
        "    d = -0.00930733913\n",
        "    e = 0.00004731582\n",
        "    f = -0.00000009054\n",
        "\n",
        "    fswilks = squat * 500 /(a+(b*bodyweight)+(c*bodyweight**2)+(d*bodyweight**3)+(e*bodyweight**4)+(f*bodyweight**5))\n",
        "    fbwilks = bench * 500 /(a+(b*bodyweight)+(c*bodyweight**2)+(d*bodyweight**3)+(e*bodyweight**4)+(f*bodyweight**5))\n",
        "    fbbr = bench/bodyweight\n",
        "    fbsr = bench/squat\n",
        "    age_class = '24-34'\n",
        "\n",
        "    if (age>=5)&(age<=12):\n",
        "        age_class = '5-12'\n",
        "    elif (age>=13)&(age<=15):\n",
        "        age_class = '13-15'\n",
        "    elif (age>=16)&(age<=17):\n",
        "        age_class = '16-17'\n",
        "    elif (age>=18)&(age<=19):\n",
        "        age_class = '18-19'\n",
        "    elif (age>=20)&(age<=23):\n",
        "        age_class = '20-23'\n",
        "    elif (age>=24)&(age<=34):\n",
        "        age_class = '24-34'\n",
        "    elif (age>=35)&(age<=39):\n",
        "        age_class = '35-39'\n",
        "    elif (age>=40)&(age<=44):\n",
        "        age_class = '40-44'\n",
        "    elif (age>=45)&(age<=49):\n",
        "        age_class = '45-49'\n",
        "    elif (age>=50)&(age<=54):\n",
        "        age_class = '50-54'\n",
        "    elif (age>=55)&(age<=59):\n",
        "        age_class = '55-59'\n",
        "    elif (age>=60)&(age<=64):\n",
        "        age_class = '60-64'\n",
        "    elif (age>=65)&(age<=69):\n",
        "        age_class = '65-69'\n",
        "    elif (age>=70)&(age<=74):\n",
        "        age_class = '70-74'\n",
        "    elif (age>=75):\n",
        "        age_class = '75-79'\n",
        "\n",
        "    weight_class = '93'\n",
        "    if bodyweight<=50:\n",
        "        weight_class = '44'\n",
        "    elif (bodyweight>50)&(bodyweight<=52):\n",
        "        weight_class = '52'\n",
        "    elif (bodyweight>52)&(bodyweight<=63):\n",
        "        weight_class = '63'\n",
        "    elif (bodyweight>63)&(bodyweight<=72):\n",
        "        weight_class = '72'\n",
        "    elif (bodyweight>72)&(bodyweight<=84):\n",
        "        weight_class = '84'\n",
        "    elif (bodyweight>84)&(bodyweight<=90):\n",
        "        weight_class = '90'\n",
        "    elif (bodyweight>90)&(bodyweight<=100):\n",
        "        weight_class = '100'\n",
        "    elif (bodyweight>100):\n",
        "        weight_class = '100+'\n",
        "\n",
        "    temp = pd.DataFrame(\n",
        "        columns=['Age', 'AgeClass', 'BodyweightKg', 'WeightClassKg', 'Best3SquatKg', 'Best3BenchKg', 'Squat Wilks', 'Bench Wilks', 'Bench:Bodyweight Ratio', 'Bench:Squat Ratio'], \n",
        "        data=[[age, age_class, bodyweight, weight_class, squat, bench, fswilks, fbwilks, fbbr, fbsr]]\n",
        "    )\n",
        "    y_pred = gbf.predict(temp)[0]\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fgbpredict(32, 100, 215, 152)"
      ]
    }
  ]
}